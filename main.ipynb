{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('future.no_silent_downcasting', True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_protein_file(file_path):\n",
    "    with open(file_path, \"r\") as file:\n",
    "        # Read the entire contents of the file\n",
    "        seq = \"\"\n",
    "        str = \"\"\n",
    "\n",
    "        sequences = []\n",
    "        strings = []\n",
    "        count = 0\n",
    "        for line in file:\n",
    "            if count < 8:\n",
    "                pass\n",
    "            count += 1\n",
    "\n",
    "            line = line.strip()\n",
    "            if line == \"<>\":\n",
    "                seq = \"\"\n",
    "                str = \"\"\n",
    "            elif line == \"<end>\" or line==\"end\":\n",
    "                sequences.append(seq)\n",
    "                strings.append(str)\n",
    "            else:\n",
    "                letters = line.split(\" \")\n",
    "                if len(letters) == 2:\n",
    "                    seq += letters[0]\n",
    "                    str += letters[1] if letters[1] != \"_\" else \"c\"\n",
    "        return sequences, strings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_seq, train_str = read_protein_file(\"data/protein-secondary-structure.train\")\n",
    "test_seq, test_str = read_protein_file(\"data/protein-secondary-structure.test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get all the test lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[306, 108, 113, 322, 62, 212, 281, 218, 198, 107, 461, 149, 220, 334, 35]"
      ]
     },
     "execution_count": 375,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "protein_lengths = []\n",
    "for i in test_seq:\n",
    "    protein_lengths.append(len(i))\n",
    "protein_lengths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create sliding windows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note. we need to split the sequences up, but since our test input is of different lengths, what do we do then?\n",
    "\n",
    "When your test data contains protein sequences of different lengths compared to your training data, you need to handle this discrepancy appropriately. Here are a few strategies you can consider:\n",
    "\n",
    "Padding:\n",
    "\n",
    "Pad shorter sequences in the test data to match the length of the longest sequence in your training data.\n",
    "You can pad the sequences with a special token (e.g., all zeros) so that the neural network can recognize them as padding.\n",
    "During inference, you would need to trim the predictions to the original length of the test sequence.\n",
    "Dynamic Input Shape:\n",
    "\n",
    "Modify your neural network architecture to accept variable-length input sequences.\n",
    "Use techniques like masking to handle variable-length sequences effectively.\n",
    "Many deep learning frameworks, such as TensorFlow and PyTorch, support dynamic input shapes and masking.\n",
    "Bucketing or Binning:\n",
    "\n",
    "Group sequences of similar lengths together and pad each group separately to the maximum length within that group.\n",
    "This approach reduces the amount of padding required, leading to more efficient training.\n",
    "You can organize your test data into buckets or bins based on sequence lengths and process each bucket separately during evaluation.\n",
    "Batch Processing:\n",
    "\n",
    "While processing batches during testing, group sequences of similar lengths together.\n",
    "This allows you to minimize padding within each batch, improving computational efficiency."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One hot encoding the sequence\n",
    "\n",
    "Encoding Amino Acids:\n",
    "\n",
    "First, you need to encode each amino acid into a numerical representation.\n",
    "Common encoding methods include one-hot encoding and embedding.\n",
    "In one-hot encoding, each amino acid is represented as a binary vector where only one element is 1 (indicating the presence of that amino acid).\n",
    "In embedding, each amino acid is mapped to a low-dimensional vector space.\n",
    "Padding:\n",
    "\n",
    "After encoding amino acids, you can proceed with padding sequences as discussed earlier.\n",
    "Pad the sequences to match the length of the longest sequence in your training data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PERFORM NEURAL NETWORK??? use RNN or CNN (keras, tensorflow, pytorch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.pnas.org/doi/epdf/10.1073/pnas.86.1.152\n",
    "\n",
    "sliding window = 17"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_based_on_windows(data_seq, data_str, W=17):\n",
    "    all_sequences = []\n",
    "    all_strings = []\n",
    "    print([len(i) for i in data_seq])\n",
    "    for i in range(len(data_seq)):\n",
    "        sequences = [data_seq[i][j:j+W] for j in range(0, len(data_seq[i]), W)]\n",
    "        strings = [data_str[i][j:j+W] for j in range(0, len(data_str[i]), W)]\n",
    "        # PADDING\n",
    "        if len(sequences[-1]) != W:\n",
    "            sequences[-1] = sequences[-1] + \"X\"*((W-len(sequences[-1])))\n",
    "        if len(strings[-1]) != W:\n",
    "            strings[-1] = strings[-1] + \"X\"*((W-len(strings[-1])))\n",
    "\n",
    "        all_sequences += sequences\n",
    "        all_strings += strings\n",
    "\n",
    "    train_df = pd.DataFrame({\"sequence\": all_sequences, \"string\": all_strings})\n",
    "    return train_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[324, 129, 125, 123, 256, 83, 111, 108, 46, 71, 118, 103, 136, 240, 207, 146, 54, 147, 29, 174, 70, 67, 149, 145, 85, 239, 30, 329, 130, 164, 129, 153, 153, 26, 124, 111, 36, 107, 293, 124, 65, 56, 247, 194, 318, 323, 85, 256, 127, 293, 146, 106, 95, 87, 75, 57, 153, 222, 325, 61, 114, 114, 181, 141, 151, 107, 184, 478, 207, 112, 237, 98, 146, 99, 415, 230, 224, 50, 316, 82, 437, 159, 138, 222, 153, 307, 333, 58, 54, 374, 498]\n",
      "[306, 108, 113, 322, 62, 212, 281, 218, 198, 107, 461, 149, 220, 334, 35]\n"
     ]
    }
   ],
   "source": [
    "train_df = split_based_on_windows(train_seq, train_str)\n",
    "test_df = split_based_on_windows(test_seq, test_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(934, 2)"
      ]
     },
     "execution_count": 378,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(190, 2)"
      ]
     },
     "execution_count": 379,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sequence</th>\n",
       "      <th>string</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>VKLVSWYDNEFGYSERV</td>\n",
       "      <td>eeeecccchhhhhhhhh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>VDLMAHMASKEXXXXXX</td>\n",
       "      <td>hhhhhhhhhhcXXXXXX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>SIPPEVKFNKPFVFLMI</td>\n",
       "      <td>cccceeecccceeeeee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>EQNTKSPLFMGKVVNPT</td>\n",
       "      <td>ecccceeeeeeeecccc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>QXXXXXXXXXXXXXXXX</td>\n",
       "      <td>cXXXXXXXXXXXXXXXX</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              sequence             string\n",
       "185  VKLVSWYDNEFGYSERV  eeeecccchhhhhhhhh\n",
       "186  VDLMAHMASKEXXXXXX  hhhhhhhhhhcXXXXXX\n",
       "187  SIPPEVKFNKPFVFLMI  cccceeecccceeeeee\n",
       "188  EQNTKSPLFMGKVVNPT  ecccceeeeeeeecccc\n",
       "189  QXXXXXXXXXXXXXXXX  cXXXXXXXXXXXXXXXX"
      ]
     },
     "execution_count": 380,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NEURAL NETWORK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {},
   "outputs": [],
   "source": [
    "by_pos_train_df = train_df['sequence'].apply(lambda x:pd.Series(list(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>G</td>\n",
       "      <td>V</td>\n",
       "      <td>G</td>\n",
       "      <td>T</td>\n",
       "      <td>V</td>\n",
       "      <td>P</td>\n",
       "      <td>M</td>\n",
       "      <td>T</td>\n",
       "      <td>D</td>\n",
       "      <td>Y</td>\n",
       "      <td>G</td>\n",
       "      <td>N</td>\n",
       "      <td>D</td>\n",
       "      <td>V</td>\n",
       "      <td>E</td>\n",
       "      <td>Y</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>G</td>\n",
       "      <td>Q</td>\n",
       "      <td>V</td>\n",
       "      <td>T</td>\n",
       "      <td>I</td>\n",
       "      <td>G</td>\n",
       "      <td>T</td>\n",
       "      <td>P</td>\n",
       "      <td>G</td>\n",
       "      <td>K</td>\n",
       "      <td>S</td>\n",
       "      <td>F</td>\n",
       "      <td>N</td>\n",
       "      <td>L</td>\n",
       "      <td>N</td>\n",
       "      <td>F</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>T</td>\n",
       "      <td>G</td>\n",
       "      <td>S</td>\n",
       "      <td>S</td>\n",
       "      <td>N</td>\n",
       "      <td>L</td>\n",
       "      <td>W</td>\n",
       "      <td>V</td>\n",
       "      <td>G</td>\n",
       "      <td>S</td>\n",
       "      <td>V</td>\n",
       "      <td>Q</td>\n",
       "      <td>C</td>\n",
       "      <td>Q</td>\n",
       "      <td>A</td>\n",
       "      <td>S</td>\n",
       "      <td>G</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C</td>\n",
       "      <td>K</td>\n",
       "      <td>G</td>\n",
       "      <td>G</td>\n",
       "      <td>R</td>\n",
       "      <td>D</td>\n",
       "      <td>K</td>\n",
       "      <td>F</td>\n",
       "      <td>N</td>\n",
       "      <td>P</td>\n",
       "      <td>S</td>\n",
       "      <td>D</td>\n",
       "      <td>G</td>\n",
       "      <td>S</td>\n",
       "      <td>T</td>\n",
       "      <td>F</td>\n",
       "      <td>K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A</td>\n",
       "      <td>T</td>\n",
       "      <td>G</td>\n",
       "      <td>Y</td>\n",
       "      <td>D</td>\n",
       "      <td>A</td>\n",
       "      <td>S</td>\n",
       "      <td>I</td>\n",
       "      <td>G</td>\n",
       "      <td>Y</td>\n",
       "      <td>G</td>\n",
       "      <td>D</td>\n",
       "      <td>G</td>\n",
       "      <td>S</td>\n",
       "      <td>A</td>\n",
       "      <td>S</td>\n",
       "      <td>G</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>929</th>\n",
       "      <td>V</td>\n",
       "      <td>Q</td>\n",
       "      <td>R</td>\n",
       "      <td>F</td>\n",
       "      <td>N</td>\n",
       "      <td>S</td>\n",
       "      <td>A</td>\n",
       "      <td>N</td>\n",
       "      <td>D</td>\n",
       "      <td>D</td>\n",
       "      <td>N</td>\n",
       "      <td>V</td>\n",
       "      <td>T</td>\n",
       "      <td>Q</td>\n",
       "      <td>V</td>\n",
       "      <td>R</td>\n",
       "      <td>T</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>930</th>\n",
       "      <td>F</td>\n",
       "      <td>Y</td>\n",
       "      <td>L</td>\n",
       "      <td>K</td>\n",
       "      <td>V</td>\n",
       "      <td>L</td>\n",
       "      <td>N</td>\n",
       "      <td>E</td>\n",
       "      <td>E</td>\n",
       "      <td>Q</td>\n",
       "      <td>R</td>\n",
       "      <td>K</td>\n",
       "      <td>R</td>\n",
       "      <td>L</td>\n",
       "      <td>C</td>\n",
       "      <td>E</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>931</th>\n",
       "      <td>I</td>\n",
       "      <td>A</td>\n",
       "      <td>G</td>\n",
       "      <td>H</td>\n",
       "      <td>L</td>\n",
       "      <td>K</td>\n",
       "      <td>D</td>\n",
       "      <td>A</td>\n",
       "      <td>Q</td>\n",
       "      <td>L</td>\n",
       "      <td>F</td>\n",
       "      <td>I</td>\n",
       "      <td>Q</td>\n",
       "      <td>K</td>\n",
       "      <td>K</td>\n",
       "      <td>A</td>\n",
       "      <td>V</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>932</th>\n",
       "      <td>K</td>\n",
       "      <td>N</td>\n",
       "      <td>F</td>\n",
       "      <td>S</td>\n",
       "      <td>D</td>\n",
       "      <td>V</td>\n",
       "      <td>H</td>\n",
       "      <td>P</td>\n",
       "      <td>E</td>\n",
       "      <td>Y</td>\n",
       "      <td>G</td>\n",
       "      <td>S</td>\n",
       "      <td>R</td>\n",
       "      <td>I</td>\n",
       "      <td>Q</td>\n",
       "      <td>A</td>\n",
       "      <td>L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>933</th>\n",
       "      <td>L</td>\n",
       "      <td>D</td>\n",
       "      <td>K</td>\n",
       "      <td>Y</td>\n",
       "      <td>N</td>\n",
       "      <td>X</td>\n",
       "      <td>X</td>\n",
       "      <td>X</td>\n",
       "      <td>X</td>\n",
       "      <td>X</td>\n",
       "      <td>X</td>\n",
       "      <td>X</td>\n",
       "      <td>X</td>\n",
       "      <td>X</td>\n",
       "      <td>X</td>\n",
       "      <td>X</td>\n",
       "      <td>X</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>934 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    0  1  2  3  4  5  6  7  8  9  10 11 12 13 14 15 16\n",
       "0    G  V  G  T  V  P  M  T  D  Y  G  N  D  V  E  Y  Y\n",
       "1    G  Q  V  T  I  G  T  P  G  K  S  F  N  L  N  F  D\n",
       "2    T  G  S  S  N  L  W  V  G  S  V  Q  C  Q  A  S  G\n",
       "3    C  K  G  G  R  D  K  F  N  P  S  D  G  S  T  F  K\n",
       "4    A  T  G  Y  D  A  S  I  G  Y  G  D  G  S  A  S  G\n",
       "..  .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. ..\n",
       "929  V  Q  R  F  N  S  A  N  D  D  N  V  T  Q  V  R  T\n",
       "930  F  Y  L  K  V  L  N  E  E  Q  R  K  R  L  C  E  N\n",
       "931  I  A  G  H  L  K  D  A  Q  L  F  I  Q  K  K  A  V\n",
       "932  K  N  F  S  D  V  H  P  E  Y  G  S  R  I  Q  A  L\n",
       "933  L  D  K  Y  N  X  X  X  X  X  X  X  X  X  X  X  X\n",
       "\n",
       "[934 rows x 17 columns]"
      ]
     },
     "execution_count": 383,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "by_pos_train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {},
   "outputs": [],
   "source": [
    "letters = [\"A\", \"C\", \"D\", \"E\", \"F\", \"G\", \"H\", \"I\", \"K\", \"L\", \"M\", \"N\", \"P\", \"Q\", \"R\", \"S\", \"T\", \"V\", \"W\", \"X\", \"Y\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [],
   "source": [
    "oh_train_df_X = pd.get_dummies(by_pos_train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_columns = []\n",
    "for i in letters:\n",
    "    columns = [str(j)+\"_\"+i for j in range(0, 17)]\n",
    "    all_columns += columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = pd.DataFrame(columns=all_columns, dtype=bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_columns = template.columns.difference(oh_train_df_X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot_encoded_full = pd.concat([oh_train_df_X, template[unique_columns]], axis=1)\n",
    "ohe_train_df_X = one_hot_encoded_full.reindex(sorted(one_hot_encoded_full.columns), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [],
   "source": [
    "by_pos_train_df_str = train_df['string'].apply(lambda x:pd.Series(list(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {},
   "outputs": [],
   "source": [
    "oh_train_df_Y = pd.get_dummies(by_pos_train_df_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {},
   "outputs": [],
   "source": [
    "letters = ['c', 'e', 'h', 'X']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_columns = []\n",
    "for i in letters:\n",
    "    columns = [str(j)+\"_\"+i for j in range(0, 17)]\n",
    "    all_columns += columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = pd.DataFrame(columns=all_columns, dtype=bool).fillna(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_columns = template.columns.difference(oh_train_df_Y.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot_encoded_full = pd.concat([oh_train_df_Y, template[unique_columns]], axis=1)\n",
    "ohe_train_df_Y = one_hot_encoded_full.reindex(sorted(one_hot_encoded_full.columns), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MAKE MATRIX OUT OF IT?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[False, False, False, ..., False, False, True],\n",
       "       [False, False, False, ..., False, False, False],\n",
       "       [False, False, False, ..., False, False, False],\n",
       "       ...,\n",
       "       [False, False, False, ..., False, False, False],\n",
       "       [False, False, False, ..., False, False, True],\n",
       "       [False, False, False, ..., False, True, False]], dtype=object)"
      ]
     },
     "execution_count": 397,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ohe_train_df_X.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe_train_df_X = ohe_train_df_X.fillna(False)\n",
    "ohe_train_df_Y = ohe_train_df_Y.fillna(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_matrix_X = ohe_train_df_X.values\n",
    "train_matrix_Y = ohe_train_df_Y.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(934, 357)"
      ]
     },
     "execution_count": 401,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_matrix_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(934, 68)"
      ]
     },
     "execution_count": 402,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_matrix_Y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SET UP NEURAL NETWORK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate some dummy data (replace with your actual data)\n",
    "# X_train: Input sequences, y_train: Corresponding labels\n",
    "X_train = np.random.rand(100, 20, 20)  # Example: 100 sequences of length 20 with 20 features\n",
    "y_train = np.random.randint(3, size=(100, 20))  # Example: 3 secondary structure classes\n",
    "\n",
    "# Define the RNN model\n",
    "model_rnn = models.Sequential([\n",
    "    layers.SimpleRNN(64, return_sequences=True, input_shape=(20, 20)),\n",
    "    layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model_rnn.compile(optimizer='adam',\n",
    "                  loss='sparse_categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model_rnn.fit(X_train, y_train, epochs=10, batch_size=32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 8ms/step - loss: 1.1870 - accuracy: 0.3200\n",
      "Epoch 2/10\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 1.1556 - accuracy: 0.3320\n",
      "Epoch 3/10\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 1.1314 - accuracy: 0.3290\n",
      "Epoch 4/10\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 1.1219 - accuracy: 0.3365\n",
      "Epoch 5/10\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 1.1177 - accuracy: 0.3505\n",
      "Epoch 6/10\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 1.1133 - accuracy: 0.3475\n",
      "Epoch 7/10\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 1.1071 - accuracy: 0.3540\n",
      "Epoch 8/10\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 1.1040 - accuracy: 0.3615\n",
      "Epoch 9/10\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 1.1017 - accuracy: 0.3740\n",
      "Epoch 10/10\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 1.0959 - accuracy: 0.3745\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x265b2629be0>"
      ]
     },
     "execution_count": 400,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # Generate some dummy data (replace with your actual data)\n",
    "# # X_train: Input sequences, y_train: Corresponding labels\n",
    "# X_train = np.random.rand(100, 20, 20)  # Example: 100 sequences of length 20 with 20 features\n",
    "# y_train = np.random.randint(3, size=(100, 20))  # Example: 3 secondary structure classes\n",
    "\n",
    "# # Define the RNN model\n",
    "# model_rnn = models.Sequential([\n",
    "#     layers.SimpleRNN(64, return_sequences=True, input_shape=(20, 20)),\n",
    "#     layers.Dense(3, activation='softmax')\n",
    "# ])\n",
    "\n",
    "# # Compile the model\n",
    "# model_rnn.compile(optimizer='adam',\n",
    "#                   loss='sparse_categorical_crossentropy',\n",
    "#                   metrics=['accuracy'])\n",
    "\n",
    "# # Train the model\n",
    "# model_rnn.fit(X_train, y_train, epochs=10, batch_size=32)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

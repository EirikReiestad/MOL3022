{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from util import read_protein_file_as_pd\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = read_protein_file_as_pd(\"data/protein-secondary-structure.train\")\n",
    "test_df = read_protein_file_as_pd(\"data/protein-secondary-structure.test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get all the test lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[306, 108, 113, 322, 62, 212, 281, 218, 198, 107, 461, 149, 220, 334, 35]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "protein_lengths = []\n",
    "for i in test_df['sequence']:\n",
    "    protein_lengths.append(len(i))\n",
    "protein_lengths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create sliding windows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note. we need to split the sequences up, but since our test input is of different lengths, what do we do then?\n",
    "\n",
    "When your test data contains protein sequences of different lengths compared to your training data, you need to handle this discrepancy appropriately. Here are a few strategies you can consider:\n",
    "\n",
    "Padding:\n",
    "\n",
    "Pad shorter sequences in the test data to match the length of the longest sequence in your training data.\n",
    "You can pad the sequences with a special token (e.g., all zeros) so that the neural network can recognize them as padding.\n",
    "During inference, you would need to trim the predictions to the original length of the test sequence.\n",
    "Dynamic Input Shape:\n",
    "\n",
    "Modify your neural network architecture to accept variable-length input sequences.\n",
    "Use techniques like masking to handle variable-length sequences effectively.\n",
    "Many deep learning frameworks, such as TensorFlow and PyTorch, support dynamic input shapes and masking.\n",
    "Bucketing or Binning:\n",
    "\n",
    "Group sequences of similar lengths together and pad each group separately to the maximum length within that group.\n",
    "This approach reduces the amount of padding required, leading to more efficient training.\n",
    "You can organize your test data into buckets or bins based on sequence lengths and process each bucket separately during evaluation.\n",
    "Batch Processing:\n",
    "\n",
    "While processing batches during testing, group sequences of similar lengths together.\n",
    "This allows you to minimize padding within each batch, improving computational efficiency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'NRDPASDQMKHWKEQRAAQKPDVLTTGGGNPVGDKLNSLTVGPRGPLLVQDVVFTDEMAHFDRERIPERVVHAKGAGAFGYFEVTHDITRYSKAKVFEHIGKRTPIAVRFSTVAGESGSADTVRDPRGFAVKFYTEDGNWDLVGNNTPIFFIRDALLFPSFIHSQKRNPQTHLKDPDMVWDFWSLRPESLHQVSFLFSDRGIPDGHRHMDGYGSHTFKLVNADGEAVYCKFHYKTDQGIKNLSVEDAARLAHEDPDYGLRDLFNAIATGNYPSWTLYIQVMTFSEAEIFPFNPFDLTKVWPHGDYPLIPVGKLVLNRNPVNYFAEVEQLAFDPSNMPPGIEPSPDKMLQGRLFAYPDTHRHRLGPNYLQIPVNCPYRARVANYQRDGPMCMMDNQGGAPNYYPNSFSAPEHQPSALEHRTHFSGDVQRFNSANDDNVTQVRTFYLKVLNEEQRKRLCENIAGHLKDAQLFIQKKAVKNFSDVHPEYGSRIQALLDKYN'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.iloc[0]['sequence']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One hot encoding the sequence\n",
    "\n",
    "Encoding Amino Acids:\n",
    "\n",
    "First, you need to encode each amino acid into a numerical representation.\n",
    "Common encoding methods include one-hot encoding and embedding.\n",
    "In one-hot encoding, each amino acid is represented as a binary vector where only one element is 1 (indicating the presence of that amino acid).\n",
    "In embedding, each amino acid is mapped to a low-dimensional vector space.\n",
    "Padding:\n",
    "\n",
    "After encoding amino acids, you can proceed with padding sequences as discussed earlier.\n",
    "Pad the sequences to match the length of the longest sequence in your training data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PERFORM NEURAL NETWORK??? use RNN or CNN (keras, tensorflow, pytorch)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

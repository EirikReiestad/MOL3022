{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "pd.set_option('future.no_silent_downcasting', True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_protein_file(file_path):\n",
    "    with open(file_path, \"r\") as file:\n",
    "        # Read the entire contents of the file\n",
    "        seq = \"\"\n",
    "        str = \"\"\n",
    "\n",
    "        sequences = []\n",
    "        strings = []\n",
    "        count = 0\n",
    "        for line in file:\n",
    "            if count < 8:\n",
    "                pass\n",
    "            count += 1\n",
    "\n",
    "            line = line.strip()\n",
    "            if line == \"<>\":\n",
    "                seq = \"\"\n",
    "                str = \"\"\n",
    "            elif line == \"<end>\" or line==\"end\":\n",
    "                sequences.append(seq)\n",
    "                strings.append(str)\n",
    "            else:\n",
    "                letters = line.split(\" \")\n",
    "                if len(letters) == 2:\n",
    "                    seq += letters[0]\n",
    "                    str += letters[1] if letters[1] != \"_\" else \"c\"\n",
    "        return sequences, strings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_seq, train_str = read_protein_file(\"data/protein-secondary-structure.train\")\n",
    "test_seq, test_str = read_protein_file(\"data/protein-secondary-structure.test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NOTE TO SELF\n",
    "Create sliding windows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note. we need to split the sequences up, but since our test input is of different lengths, what do we do then?\n",
    "\n",
    "When your test data contains protein sequences of different lengths compared to your training data, you need to handle this discrepancy appropriately. Here are a few strategies you can consider:\n",
    "\n",
    "Padding:\n",
    "\n",
    "Pad shorter sequences in the test data to match the length of the longest sequence in your training data.\n",
    "You can pad the sequences with a special token (e.g., all zeros) so that the neural network can recognize them as padding.\n",
    "During inference, you would need to trim the predictions to the original length of the test sequence.\n",
    "Dynamic Input Shape:\n",
    "\n",
    "Modify your neural network architecture to accept variable-length input sequences.\n",
    "Use techniques like masking to handle variable-length sequences effectively.\n",
    "Many deep learning frameworks, such as TensorFlow and PyTorch, support dynamic input shapes and masking.\n",
    "Bucketing or Binning:\n",
    "\n",
    "Group sequences of similar lengths together and pad each group separately to the maximum length within that group.\n",
    "This approach reduces the amount of padding required, leading to more efficient training.\n",
    "You can organize your test data into buckets or bins based on sequence lengths and process each bucket separately during evaluation.\n",
    "Batch Processing:\n",
    "\n",
    "While processing batches during testing, group sequences of similar lengths together.\n",
    "This allows you to minimize padding within each batch, improving computational efficiency."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One hot encoding the sequence\n",
    "\n",
    "Encoding Amino Acids:\n",
    "\n",
    "First, you need to encode each amino acid into a numerical representation.\n",
    "Common encoding methods include one-hot encoding and embedding.\n",
    "In one-hot encoding, each amino acid is represented as a binary vector where only one element is 1 (indicating the presence of that amino acid).\n",
    "In embedding, each amino acid is mapped to a low-dimensional vector space.\n",
    "Padding:\n",
    "\n",
    "After encoding amino acids, you can proceed with padding sequences as discussed earlier.\n",
    "Pad the sequences to match the length of the longest sequence in your training data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PERFORM NEURAL NETWORK??? use RNN or CNN (keras, tensorflow, pytorch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.pnas.org/doi/epdf/10.1073/pnas.86.1.152\n",
    "\n",
    "sliding window = 17"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create sliding windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_based_on_windows(data_seq, data_str, W=17):\n",
    "    all_sequences = []\n",
    "    all_strings = []\n",
    "    for i in range(len(data_seq)):\n",
    "        sequences = [data_seq[i][j:j+W] for j in range(0, len(data_seq[i]), W)]\n",
    "        strings = [data_str[i][j:j+W] for j in range(0, len(data_str[i]), W)]\n",
    "        # PADDING\n",
    "        if len(sequences[-1]) != W:\n",
    "            sequences[-1] = sequences[-1] + \"X\"*((W-len(sequences[-1])))\n",
    "        if len(strings[-1]) != W:\n",
    "            strings[-1] = strings[-1] + \"X\"*((W-len(strings[-1])))\n",
    "\n",
    "        all_sequences += sequences\n",
    "        all_strings += strings\n",
    "\n",
    "    train_df = pd.DataFrame({\"sequence\": all_sequences, \"string\": all_strings})\n",
    "    return train_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = split_based_on_windows(train_seq, train_str)\n",
    "test_df = split_based_on_windows(test_seq, test_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One hot encode the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_matrix_from_letter_cols(letters, df):\n",
    "    all_columns = []\n",
    "    for i in letters:\n",
    "        columns = [str(j)+\"_\"+i for j in range(0, 17)]\n",
    "        all_columns += columns\n",
    "\n",
    "    template = pd.DataFrame(columns=all_columns, dtype=bool)\n",
    "    unique_columns = template.columns.difference(df.columns)\n",
    "\n",
    "    one_hot_encoded_full = pd.concat([df, template[unique_columns]], axis=1).fillna(False)\n",
    "    ohe_df = one_hot_encoded_full.reindex(sorted(one_hot_encoded_full.columns), axis=1).astype(int)\n",
    "    return ohe_df.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ohe_matrix(df):\n",
    "    X_letters = [\"A\", \"C\", \"D\", \"E\", \"F\", \"G\", \"H\", \"I\", \"K\", \"L\", \"M\", \"N\", \"P\", \"Q\", \"R\", \"S\", \"T\", \"V\", \"W\", \"X\", \"Y\"]\n",
    "    Y_letters = ['c', 'e', 'h', 'X']\n",
    "\n",
    "    by_pos_df = df['sequence'].apply(lambda x:pd.Series(list(x)))\n",
    "    ohe_df_X = pd.get_dummies(by_pos_df)\n",
    "    ohe_X = get_matrix_from_letter_cols(X_letters, ohe_df_X)\n",
    "\n",
    "    by_pos_df = df['string'].apply(lambda x:pd.Series(list(x)))\n",
    "    ohe_df_Y = pd.get_dummies(by_pos_df)\n",
    "    ohe_Y = get_matrix_from_letter_cols(Y_letters, ohe_df_Y)\n",
    "\n",
    "    return ohe_X, ohe_Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ohe_X, train_ohe_Y = get_ohe_matrix(train_df)\n",
    "test_ohe_X, test_ohe_Y = get_ohe_matrix(test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/24 [==============================] - 1s 7ms/step - loss: 71.3121 - accuracy: 0.0187 - val_loss: 70.4473 - val_accuracy: 0.0160\n",
      "Epoch 2/10\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 69.9108 - accuracy: 0.0080 - val_loss: 69.8063 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/10\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 71.0182 - accuracy: 0.0040 - val_loss: 72.9486 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/10\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 76.5235 - accuracy: 0.0000e+00 - val_loss: 79.6916 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/10\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 84.2313 - accuracy: 0.0000e+00 - val_loss: 87.3715 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/10\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 92.7112 - accuracy: 0.0000e+00 - val_loss: 94.8532 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/10\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 101.2570 - accuracy: 0.0027 - val_loss: 102.6823 - val_accuracy: 0.0053\n",
      "Epoch 8/10\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 110.5788 - accuracy: 0.0281 - val_loss: 112.6501 - val_accuracy: 0.0053\n",
      "Epoch 9/10\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 121.8507 - accuracy: 0.0469 - val_loss: 123.4276 - val_accuracy: 0.0107\n",
      "Epoch 10/10\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 134.7558 - accuracy: 0.0295 - val_loss: 134.2218 - val_accuracy: 0.0749\n",
      "6/6 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 1, ..., 1, 1, 1],\n",
       "       [0, 1, 1, ..., 1, 1, 1],\n",
       "       [0, 1, 1, ..., 1, 1, 1],\n",
       "       ...,\n",
       "       [0, 1, 1, ..., 1, 1, 1],\n",
       "       [0, 1, 1, ..., 1, 1, 1],\n",
       "       [0, 1, 1, ..., 1, 1, 1]])"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = models.Sequential([\n",
    "    layers.Dense(units=train_ohe_Y.shape[1],input_shape=(train_ohe_X.shape[1],), activation=\"relu\"),\n",
    "    layers.Dense(train_ohe_Y.shape[1], activation='sigmoid')\n",
    "\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer= \"adam\", metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(train_ohe_X, train_ohe_Y, epochs=10, batch_size=32, validation_split=0.2)\n",
    "predictions = model.predict(test_ohe_X)\n",
    "output = np.where(predictions > 0.5, 1, 0)\n",
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert the prediction back"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_mat_back_to_seq(mat):\n",
    "    letters = ['c', 'e', 'h', 'X']\n",
    "\n",
    "    all_columns = []\n",
    "    for i in letters:\n",
    "        columns = [str(j)+\"_\"+i for j in range(0, 17)]\n",
    "        all_columns += columns\n",
    "\n",
    "    template = pd.DataFrame(mat, columns=all_columns, dtype=bool)\n",
    "\n",
    "    strings = []\n",
    "    for i in range(mat.shape[0]):\n",
    "        string = \"\"\n",
    "        for j in range(mat.shape[1]//len(letters)):\n",
    "            for k in letters:\n",
    "                if template[f\"{j}_{k}\"].iloc[i]:\n",
    "                    string+=k\n",
    "                    break\n",
    "        strings.append(string)\n",
    "    return strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "190\n"
     ]
    }
   ],
   "source": [
    "pred_sequences = convert_mat_back_to_seq(output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['predict'] = pred_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sequence</th>\n",
       "      <th>string</th>\n",
       "      <th>predict</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ENLKLGFLVKQPEEPWF</td>\n",
       "      <td>cccccceeeccccccch</td>\n",
       "      <td>ecccccccccccccccc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>QTEWKFADKAGKDLGFE</td>\n",
       "      <td>hhhhhhhhhhhhhcccc</td>\n",
       "      <td>ecccccccccccccccc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>VIKIAVPDGEKTLNAID</td>\n",
       "      <td>cceeeccchhhhhhhhh</td>\n",
       "      <td>ecccccccccccccccc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SLAASGAKGFVICTPDP</td>\n",
       "      <td>hhhhccccccccccccc</td>\n",
       "      <td>ecccccccccccccccc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>KLGSAIVAKARGYDMKV</td>\n",
       "      <td>cccchhhhhhhhhcccc</td>\n",
       "      <td>ecccccccccccccccc</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            sequence             string            predict\n",
       "0  ENLKLGFLVKQPEEPWF  cccccceeeccccccch  ecccccccccccccccc\n",
       "1  QTEWKFADKAGKDLGFE  hhhhhhhhhhhhhcccc  ecccccccccccccccc\n",
       "2  VIKIAVPDGEKTLNAID  cceeeccchhhhhhhhh  ecccccccccccccccc\n",
       "3  SLAASGAKGFVICTPDP  hhhhccccccccccccc  ecccccccccccccccc\n",
       "4  KLGSAIVAKARGYDMKV  cccchhhhhhhhhcccc  ecccccccccccccccc"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
